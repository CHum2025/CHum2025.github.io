---
layout: single
title: Call for Papers
permalink: /call-for-papers.html
---

<div class="page__content">

<p style="font-size: 120%">CHum 2025 invites submissions
of <strong>long and short papers on original, unpublished
work</strong> on any topic relevant to the computational processing of
humor.  All accepted submissions will appear in the published
proceedings and be presented as talks at the virtual workshop.</p>

<h2>Scope and topics</h2>

<p>CHum 2025 aims to foster further work on modeling the processes of
humor with current methods in computational linguistics and natural
language processing, against the theoretical backdrop of humor
research and with reference to relevant corpora of textual, visual,
and multimodal materials.  A principal goal of the workshop is to
unite researchers who can together probe the limits of various meaning
representations&mdash;symbolic, neural, and hybrid&mdash;for humor
processing.</p>

<p>We welcome papers on a range of topics, including but not limited to:</p>

<dl>
  <dt>LLMs, knowledge representation</dt>
  <dd>Using knowledge graphs or symbolic knowledge for humor
detection, creation, and/or appreciation; using LLMs and/or symbolic
knowledge to interpret the reasoning mechanism of joke types;
distilling and distinguishing implicit and explicit symbolic knowledge
from LLMs needed for humor processing; systematic description of the
gaps in LLMs, symbolic, or neurosymbolic approaches for humor
processing; new unified representations for symbolic and neural
meaning representation, from multidisciplinary humor perspective, in
particular for humor generation.</dd>
  <dt>Resources and evaluation</dt>
  <dd>Datasets (particularly multimodal ones) useful for training,
fine-tuning, or testing general-purpose or task-specific humor models
and algorithms; evaluation methodologies and metrics for particular
humor tasks or humor types.</dd>
  <dt>Human-computer interaction</dt>
  <dd>User interfaces for humor-aware software such as games or
(possibly embodied) computational conversational agents, where models
or algorithms must detect and classify humor in the human input and
react appropriately or generate\slash recall reciprocating humor and
inject it into the interaction.</dd>
  <dt>Computer-mediated communication</dt>
  <dd>Similar to the previous area, but where the interactions are
between humans, with the computer serving as the medium or
facilitator.</dd>
  <dt>Assisted content creation</dt>
  <dd>Systems for (interactively) suggesting humorous additions or
variants to human-generated semiotic content (text, images, sound,
video, or their combination).</dd>
  <dt>Machine and computer-assisted translation</dt>
  <dd>Systems to produce, or assist humans in the production of,
translation of texts containing humor in particular.</dd>
  <dt>Digital humanities applications</dt>
  <dd>(Semi-)automatic methods for assisting humanities scholars with
the retrieval, identification, classification, and analysis of humor
in literature, music, film, or other (possibly multimodal) media.</dd>
  <dt>Formal modeling of humor</dt>
  <dd>Computational resources, models, and methods that allow
researchers in the arts and (social) sciences to formalize and test
their theories of humor.</dd>
  <dt>Proof-of-concept humor detection and classification</dt>
  <dd>Focused academic proofs of concept of certain algorithms and
resources against a humor-related benchmark; such fundamental research
serving to provide useful building blocks for the above-noted
downstream tasks.</dd>
</dl>

<h2>Submission instructions</h2>

<p>Papers should be formatted according to the
same <strong><a href="https://coling2025.org/calls/submission_guidlines/">guidelines
for the main COLING 2025 conference papers</a></strong> and submitted
online through
the <strong><a href="https://softconf.com/coling2025/CompHum25/">CHum
2025 submission site on
START</a></strong>: <a href="https://softconf.com/coling2025/CompHum25/">https://softconf.com/coling2025/CompHum25/</a>.</p>

<h2>Important Dates</h2>

<p>All deadlines are at
23:59 <a href="https://www.timeanddate.com/time/zone/timezone/utc-12">UTC-12:00</a>
("anywhere on Earth").</p>

<table>
  <tr><th>Initial submission</th><td>November 15, 2024</td></tr>
  <tr><th>Notification of acceptance</th><td>December 2, 2024</td></tr>
  <tr><th>Camera-ready submission</th><td>December 13, 2024</td></tr>
  <tr><th>Workshop</th><td>January 19 or 20, 2025</td></tr>
</table>
</div>
