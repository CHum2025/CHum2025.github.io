---
layout: splash
header:
  overlay_image: /assets/images/header.jpeg  # Replace with the actual path to your image
  overlay_color: "#333"  # Optional: A hex color for the overlay (if not using an image)
  overlay_filter: 0.5  # Optional: A number between 0 and 1 to specify the opacity of the overlay
title: "1st Workshop on Computational Humor"
---

<div class="page__content">
    <section id="Workshop Scope">
        <h2>Overview</h2>
      <p>The impressive recent progress in generative AI has enabled new
approaches to complex tasks that can be thought of as essentially human,
such as producing or understanding humor. For its part, humor research has
become a mature, interdisciplinary field, both in theoretical advances
across disciplines such as psychology, linguistics, and sociology, and in a
breadth of purview and empirical support. Our workshop aims to foster
further work on modeling the processes of humor with current methods in
computational linguistics and natural language processing, against the
theoretical backdrop of humor research and with reference to relevant
corpora of textual, visual, and multimodal materials.</p>

<p>Being more dependent on context and inference than straightforward forms of
communication, humor poses particular challenges for probabilistic
approaches. For these and other reasons, it has long served as a special
field of application for computational linguistic&mdash;understanding humor
has often been referred to as "AI complete" (Raskin 1988)&mdash;and as
such could be considered a potential test case for Artificial General
Intelligence.</p>

<p>Computational humor (Winters 2021) is especially hard as analysis, where it
must be assumed to require extensive background knowledge to reproduce the
complex, para-logical inferences that are one of the necessary elements of
humor. Computational humor analysis with modest scope is nevertheless
attempted (e.g., Hessel 2022, Xu 2024), but often culminates in
classification tasks of unknown usefulness. Successes in computational
humor generation (e.g., Gorenz & Schwarz 2024, Jentzsch 2023), on the other
hand, are possible with limited resources, often in combination with
prompt-engineering LLMs, and can be greatly aided by post-editing or other
"co-creative" approaches (Branch 2024, Mirowski 2024). Humor generation
also succeeds because much of the humor work is on the part of the hearer,
who dutifully succeeds when a text is marked as humor, even if the text
might not have been imbued with all the necessary and sufficient components
to be humor-carrying by the computational generation system.</p>

<p>There are arguments that humor relies on background knowledge that may not
be available from a single modality, such as a text, and as such is not
machine-learnable in a straightforward manner. With this in mind, a
principal goal of this workshop is to unite researchers who can together
probe the limits of various meaning representations&mdash;symbolic, neural,
and hybrid (e.g., Toplyn 2023, Amin 2020, Zhang 2020, Dong 2024)&mdash;for
humor processing.</p>

<p>The workshop will welcome contributions on any topic relevant to
the computational processing of humor, including (but not limited to)
the following themes and application areas.  Particularly encouraged
are submissions describing inter- or multi-disciplinary work, whether
completed or in progress, and position papers that critically discuss
the past, present, and future of computational humor systems.</p>

<ul>
<li><em>LLMs, knowledge representation</em>: Using knowledge graphs or
symbolic knowledge for humor detection, creation, and/or appreciation;
using LLMs and/or symbolic knowledge to interpret the reasoning mechanism
of joke types; distilling and distinguishing implicit and explicit symbolic
knowledge from LLMs needed for humor processing; systematic description of
the gaps in LLMs, symbolic, or neurosymbolic approaches for humor
processing; new unified representations for symbolic and neural meaning
representation, from multidisciplinary humor perspective, in particular for
humor generation.
<li><em>Resources and
evaluation</em>: Datasets (particularly multimodal ones) useful for training,
fine-tuning, or testing general-purpose or task-specific humor models and
algorithms; evaluation methodologies and metrics for particular humor tasks
or humor types.</li>
<li><em>Human-computer interaction</em>: User interfaces for humor-aware
software such as games or (possibly embodied) computational conversational
agents, where models or algorithms must detect and classify humor in the
human input and react appropriately or generate\slash recall reciprocating
humor and inject it into the interaction.</li>
<li><em>Computer-mediated communication</em>: Similar to the previous area,
but where the interactions are between humans, with the computer serving as
the medium or facilitator.</li>
<li><em>Assisted content creation</em>: Systems for (interactively)
suggesting humorous additions or variants to human-generated semiotic
content (text, images, sound, video, or their combination).</li>
<li><em>Machine and
computer-assisted translation</em>: Systems to produce, or assist humans in the
production of, translation of texts containing humor in particular.</li>
<li><em>Digital humanities applications</em>: (Semi-)automatic methods
for assisting humanities scholars with the retrieval, identification,
classification, and analysis of humor in literature, music, film, or other
(possibly multimodal) media.</li>
<li><em>Formal modeling of humor</em>:
Computational resources, models, and methods that allow researchers in the
arts and (social) sciences to formalize and test their theories of humor.</li>
<li><em>Proof-of-concept humor detection and classification</em>: Focused
academic proofs of concept of certain algorithms and resources against a
humor-related benchmark; such fundamental research serving to provide
useful building blocks for the above-noted downstream tasks.</li>
</ul>
      </section>
  
    <p>
    For paper submissions, please use the following link: 
    <a href="https://softconf.com/coling2025/CompHum25/">Submission Link</a>.
    </p>


    <section id="Invited Speakers">
        <h2>Invited Speakers</h2>
      <div class="invited_speaker"> 
          <div class="invited_speaker">
            <img src="/assets/images/Salvatore.jpg" alt="Salvatore Attardo" width="750" >
            <p><a href="https://www.tamuc.edu/people/salvatore-attardo/">Salvatore Attardo</a></p>
            <p>Texas A&M University-Commerce</p>
            <h3></h3>
            <p></p>
            </div>
          <div class="invited_speaker">
            <img src="/assets/images/tony.jpg" alt="Tony Veale" class="custom-position">
            <p><a href="https://people.ucd.ie/tony.veale">Tony Veale</a></p>
            <p>University College Dublin</p>
            <h3></h3>
            <p></p>
          </div>
        <div class="invited_speaker"> 
          <div class="invited_speaker">
            <img src="/assets/images/ruch.png" alt="Willibald Ruch">
            <p><a href="https://www.psychologie.uzh.ch/de/institut/ueber-uns/angehoerige/emeriti/perspsy/team/ruch.html">Willibald Ruch</a></p>
            <p>University of Zurich</p>
            <h3></h3>
            <p></p>
          </div>  
    </section>

    <section id="Organizers">
        <h2>Organizers</h2>
        <div class="organizers">
          <!-- Row 1 -->
          <div class="organizer">
            <img src="/assets/images/Hempelmann2018.jpg" alt="Christian F. Hempelmann">
            <p><a href="https://www.tamuc.edu/people/christian-f-hempelmann/">Christian F. Hempelmann</a></p>
            <p>Texas A&M University-Commerce</p>
          </div>
          <div class="organizer">
            <img src="/assets/images/Julia.jpeg" alt="Julia Rayz">
            <p><a href="https://polytechnic.purdue.edu/profile/taylo108">Julia Rayz</a></p>
            <p>Purdue University</p>
          </div>
          <div class="organizer">
            <img src="/assets/images/tdong.jpg" alt="Tiansi Dong">
            <p><a href="https://tiansidr.github.io/">Tiansi Dong</a></p>
            <p>Fraunhofer IAIS</p>
          </div>
          
          <div class="organizer">
            <img src="/assets/images/tristan.jpeg" alt="Tristan Miller">
            <p><a href="https://logological.org/">Tristan Miller</a></p>
            <p>University of Manitoba</p>
          </div>
        </div>
    </section>
    <section id="Program Committee">
	    <h2>Program Committee</h2> (confirmed so far)
      <ul>
	<li><a href="https://polytechnic.purdue.edu/facilities/akranlu/people">Rey Alejandro Gonzalez</a>, Purdue University</li>
    <li>Monika, JP Morgan</li>
	<li><a href="https://scholar.google.com/citations?user=JB8mHVUAAAAJ&hl=en">Amir Ori</a>, UT Permian Basin</li>
    <li><a href="https://www.tamuc.edu/people/max-petrenko-ph-d/">Max Petrenko</a>, Amazon</li>
    <li><a href="https://polytechnic.purdue.edu/profile/tringenb">Tatiana Ringenberg</a>, Purdue University</li>
    <li><a href="https://twentylanemedia.com/">Joe Toplyn</a>, Twenty Lane Media</li>
</ul>
    </section>
		<section id="Schedule">
			<h2>Schedule</h2>
		<ul>
			<li>Submission Deadline: 15 November 2024</li>
<li>Notifications of Acceptance: 2 December 2024</li>
<li>Camera Ready Deadline: 13 December 2024</li>
		</ul>
		</section>
</div>
